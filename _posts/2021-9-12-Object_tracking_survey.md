---
redirect_from: /_posts/2021-9-12-Object_tracking_survey.md/
title: Object_tracking_survey
tags:
  - Python
  - AI
  - ComputerVision
---
# 目标追踪

## 1. 介绍

计算机视觉（CV）利用摄像头来模拟人眼对对象的提取、识别和跟踪。其中视觉跟踪是最具挑战性的任务之一。计算机视觉中的问题，目标追踪可以为机器人提供对指定target的跟踪、定位和识别，并且可以将目标或环境的参数提供给控制器以供后续使用。

### 1.1 任务分类

#### 根据背景的状态分为：  

静态背景下的目标追踪： 静态背景下的目标跟踪指摄像头是固定的，其采集的视野中背景是静止的，如在十字路口的固定摄像头。

动态背景下的目标追踪： 摄像头采集的视野中背景和目标都是在变化的。

#### 根据追踪目标的数量分为：  

**单目标追踪：**在视频的第一帧给定任意一个目标的矩形框，在后续视频中跟踪这个目标。

**多目标追踪：**追踪多个目标的大小和位置且每一帧中目标的数量和位置都可能变化。

#### 根据任务计算类型分为：  

**在线跟踪：**在线跟踪需要实时处理任务，通过过去和现在帧来跟踪未来帧中物体的位置。

**离线跟踪：**离线跟踪是离线处理任务，可以通过过去、现在和未来的帧来推断物体的位置，因此准确率会在线跟踪高。

### 1.2 任务难点

**图像噪声** 光照强度变化, 目标快速运动, 低分辨率等情况会导致图像模型, 尤其是在运动目标与背景相似的情况下更为明显。因此, 选择有效的特征对目标和背景进行区分非常必要。  

**形态变化** 姿态变化是目标跟踪中常见的干扰问题。运动目标发生姿态变化时, 会导致它的特征以及外观模型发生改变, 容易导致跟踪失败。例如:体育比赛中的运动员、马路上的行人。  

**尺度变化** 尺度的自适应也是目标跟踪中的关键问题。当目标尺度缩小时, 由于跟踪框不能自适应跟踪, 会将很多背景信息包含在内, 导致目标模型的更新错误:当目标尺度增大时, 由于跟踪框不能将目标完全包括在内, 跟踪框内目标信息不全, 也会导致目标模型的更新错误。因此, 实现尺度自适应跟踪是十分必要的。  

**遮挡与消失** 目标在运动过程中可能出现被遮挡或者短暂的消失情况。当这种情况发生时, 跟踪框容易将遮挡物以及背景信息包含在跟踪框内, 会导致后续帧中的跟踪目标漂移到遮挡物上面。若目标被完全遮挡时, 由于找不到目标的对应模型, 会导致跟踪失败。  

**实时处理需求** 目标追踪往往要求做到尽可能实时地跟踪未来帧中物体的位置，需要在跟踪过程中不断地更新外观模型。  

## 2. 目标追踪数据集

### 2.1 目前常用评价指标

#### 06年提出的CLEAR MOT 

现在用的**最多**的就是**MOTA**。但是这个指标FN、FP的权重占比很大，更多衡量的是**检测的质量**，而不是**跟踪的效果**。（IDSW为ID跳变率）  

$$MOTA = 1 - \frac {\sum(FN+FP+IDSW)}{\sum GT} \in (-\infty,1] $$  

$$MOTP = \frac{\sum_{t,i}d_{t,i}}{\sum_tc_t}$$

#### 16年提出的ID scores。

因为都是基于匹配的指标，所以能更好的衡量**数据关联**的好坏。  

Identification precision: $IDP = \frac{IDTP}{IDTP+IDFP}$

Identification recall: $IDR = \frac{IDTP}{IDTP+IDFN}$

Identification F1:  $IDF1 = \frac{2}{\frac{1}{IDP}+\frac{1}{IDR}} = \frac{2IDTP}{2IDTP+IDFP+IDFN}$

### 2.2 数据集

#### MOT数据集

数据集用的最多的是 **MOTChallenge**，专注于行人追踪的。 [https://motchallenge.net/](https://motchallenge.net/)

- 15 年的都是采集的老的数据集的视频做的修正。参考论文：MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking『[https://arxiv.org/abs/1504.01942](https://arxiv.org/abs/1504.01942)』
- 16 年的是全新的数据集，相比于 15 年的行人密度更高、难度更大。特别注意这个 **DPM 检测器**，效果非常的差，全是漏检和误检。参考论文：MOT16: A Benchmark for Multi-Object Tracking：『[https://arxiv.org/abs/1603.00831](https://arxiv.org/abs/1603.00831)』
- 17 年的视频和 16 年一模一样，只是提供了**三个检测器**，相对来说更公平。也是现在论文的**主流数据集**。
- 19 年的是针对特别拥挤情形的数据集，只有 CVPR19 比赛时才能提交。  

#### KITTI数据集

KITTI 数据集的是针对自动驾驶的数据集，有汽车也有行人，在 MOT 的论文里用的很少。[http://www.cvlibs.net/datasets/kitti/index.php](http://www.cvlibs.net/datasets/kitti/index.php)



#### VOT数据集

VOTChallenge，单目追踪数据集。https://www.votchallenge.net/

## 3. 目标追踪算法

### 3.1 目标追踪算法基本原理

目标跟踪算法一般包括四个部分：特征提取、运动模型、外观模型、在线更新机制。

#### 特征提取(Feature Extraction)

特征提取，用于提取图像目标的特征，特征一般要求既能较好地描述跟踪目标又能快速计算。常见的图像特征有灰度特征、颜色特征、纹理特征、Haar-like 矩形特征等；

#### 运动模型(Motion Model)

运动模型旨在描述帧与帧目标运动状态之间的关系，显式或隐式地在视频帧中预测目标图像区域，并给出一组可能的候选区域．经典的运动模型有均值漂移(Mean shift)、滑动窗口(Slide window)、卡尔曼滤波( Kalman Filtering)、粒子滤波( Particle Filtering) 等；

####  外观模型(Appearance Model)

外观模型的作用是在当前帧中判决候选图像区域是被跟踪目标的可能性。提取图像区域的视觉特征，输入外观模型进行匹配或决策，最终确定被跟踪目标的空间位置。在视觉跟踪的4 个基本组成中，外观模型处于核心地位，如何设计一个鲁棒的外观模型是在线视觉跟踪算法的关键；

#### 在线更新机制(Online Update Mechanism)

为了捕捉目标( 和背景) 在跟踪过程中的变化，目标跟踪需要包含一个在线更新机制，在跟踪过程中不断更新外观模型．常见的外观模型更新方式有模板更新、增量子空间学习算法及在线分类器等．如何设计一个合理的在线更新机制，既能捕捉目标( 和背景) 的变化又不会导致模型退化，也是目标跟踪研究的一个关键问题。

### 3.2  算法分类

---

根据模式分为两类

#### 生成式(generative)模型

通过在线学习方式建立目标模型，然后使用模型搜索重建误差最小的图像区域，完成目标定位。这一类方法没有考虑目标的背景信息，图像信息没有得到较好的应用。通俗点讲就是在当前帧对目标区域建模，下一帧寻找与模型最相似的区域就是预测位置，比较著名的有卡尔曼滤波，粒子滤波，mean-shift等。

#### 判别式(discrimination)模型

将目标跟踪看作是一个二元分类问题，同时提取目标和背景信息用来训练分类器，将目标从图像序列背景中分离出来，从而得到当前帧的目标位置。CV中的经典套路图像特征+机器学习， 当前帧以目标区域为正样本，背景区域为负样本，机器学习方法训练分类器，下一帧用训练好的分类器找最优区域：与生成类方法最大的区别是，分类器采用机器学习，训练中用到了背景信息，这样分类器就能专注区分前景和背景，所以判别类方法普遍都比生成类好。

-----

按时间分为三类

#### 经典跟踪算法

例如：光流法、Meanshift、粒子滤波

缺点：未考虑背景信息，目标遮挡、光照、噪声等影响容易跟踪失败；算法速度慢，无法满足实时化要求。

#### 基于核相关滤波的跟踪算法

将通信领域的相关滤波引入

例如：MOSSE、CSK、KCF、BACF、SAMF

#### 基于深度学习的跟踪算法

在大数据背景下，利用深度学习训练网络模型，得到的卷积特征输出表达能力更强。在目标跟踪上，初期的应用方式是把网络学习到的特征，直接应用到相关滤波或 Struck 的跟踪框架里面，从而得到更好的跟踪结果，比如前面提到的 DeepSRDCF 方法。本质上卷积输出得到的特征表达，更优于 HOG 或 CN 特征，这也是深度学习的优势之一，但同时也带来了计算量的增加。

